[
  {
    "objectID": "nb/lec1.html",
    "href": "nb/lec1.html",
    "title": "Lecture 1 - Monte Carlo",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats",
    "crumbs": [
      "Home",
      "Lecture 1 - Monte Carlo"
    ]
  },
  {
    "objectID": "nb/lec1.html#introduction",
    "href": "nb/lec1.html#introduction",
    "title": "Lecture 1 - Monte Carlo",
    "section": "Introduction",
    "text": "Introduction\n\nExample 1.2: simple binomial test\n\nnum_simulation = 1000\nnum_tosses = 6\nobs_num_heads = 1\n\nall_results = np.zeros(num_simulation)\n\nfor cur_sim in range(num_simulation):\n    cur_tosses = np.zeros(num_tosses)\n    for i in range(num_tosses):\n        cur_tosses[i] = np.random.choice([0, 1])\n\n    all_results[cur_sim] = np.sum(cur_tosses)\n\nsim_pval = np.sum(all_results &lt;= obs_num_heads) / num_simulation\n\nprint(f\"Simulated p-value: {sim_pval}\")\n\nSimulated p-value: 0.106\n\n\nPlotting the distribution of the test statistic under the null\n\nbins = np.arange(all_results.min(), all_results.max() + 2) - 0.5\n\nplt.hist(all_results, rwidth=.7, bins=bins);\nplt.axvline(obs_num_heads, color='red');\nplt.show()",
    "crumbs": [
      "Home",
      "Lecture 1 - Monte Carlo"
    ]
  },
  {
    "objectID": "nb/lec1.html#permutation-tests",
    "href": "nb/lec1.html#permutation-tests",
    "title": "Lecture 1 - Monte Carlo",
    "section": "Permutation tests",
    "text": "Permutation tests\n\nExample 1.3: A/B Testing\nAlso known as two sample testing.\nConsider an A/B test where each user outcome is binary (click = 1, no click = 0). We want to test whether the click-through rates differ between the two groups:\nH_0: p_A = p_B \\quad \\text{vs.} \\quad H_1: p_A\\neq p_B\nA permutation test constructs a null distribution by repeatedly shuffling the A/B labels.\nUnder the null hypothesis, the labels do not carry information about CTR; that is, the outcomes are exchangeable across groups. Therefore, conditional on the observed outcomes, every reassignment of the A/B labels (keeping the group sizes fixed) is equally likely.\nTo test H_0:\n\nCompute a test-statistic from observed data (e.g. T^{obs} = |\\widehat{p}_A - \\widehat{p}_B|)\nRandomly shuffle the A/B labels many times and recompute test statistic each time\nCompare T^{obs} to the permutation distribution to obtain a p-value:\n\np\\text{-val} = \\frac{1}{S}\\sum_{s=1}^S \\mathbb{I}(T^{(s)} \\geq T^{obs})\n\nn_sim = 1000\n\nmy_viewsA = 98\nmy_viewsB = 162\nall_views = my_viewsA + my_viewsB\n\nn_impsA = 1000\nn_impsB = 2000\nall_imps = n_impsA + n_impsB\n\nobs_T = abs(my_viewsA / n_impsA - my_viewsB / n_impsB)\n\nnull_Ts = np.zeros(n_sim) ## what we called \"all_results\" from before\n\nfor cur_sim in range(n_sim):\n    pool = np.array([1] * all_views + [0] * (all_imps - all_views))\n    impsA = np.random.choice(pool, n_impsA, replace=False)\n    viewsA = np.sum(impsA)\n    viewsB = all_views - viewsA\n\n    diff = viewsA / n_impsA - viewsB / n_impsB\n    null_Ts[cur_sim] = diff\n\nsim_pval = np.sum(np.abs(null_Ts) &gt;= np.abs(obs_T)) / n_sim\n\nprint(f\"Simulated p-value: {sim_pval}\")\n\nplt.hist(null_Ts, bins=12)\nplt.axvline(abs(obs_T), color='red')\nplt.show()\n\nSimulated p-value: 0.137\n\n\n\n\n\n\n\n\n\n\n\nExample 1.4: independence test for contingency tables\nWe have paired data (X_1,Y_1), \\dots, (X_n, Y_n).\nWe can use permutations to test:\nH_0: X \\text{ independent of } Y \\quad \\text{vs.}\\quad H_1: X \\text{ not independent of } Y\nUnder the null, shuffling which values are paired does not change the distribution (because X and Y are independent).\nThat is, under the null, (X_4, Y_1), (X_{32}, Y_2), ... (X_5, Y_n) has the same distribution as the original data.\n\nK1 = 3\nK2 = 2\n\ncon_table = [[350, 1200, 450], \n             [20, 120, 60]]\n\ncon_table = np.array(con_table)\n\ncolumn_sums = np.sum(con_table, axis=0)\nrow_sums = np.sum(con_table, axis=1)\n\n\n## compute chi-squared test statistic\nE = np.zeros((K2, K1))\nfor i in range(K2):\n    for j in range(K1):\n        E[i, j] = row_sums[i] * column_sums[j] / np.sum(con_table)\n\nobs_T = np.sum((con_table - E)**2 / E)\n\nn = int(np.sum(con_table))\n\n\n## convert contingency table to data pairs\ndata_pairs = []\nfor i in range(K2):\n    for j in range(K1):\n        for _ in range(int(con_table[i, j])):\n            data_pairs.append([i, j])\ndata_pairs = np.array(data_pairs)\n\n\nn_sim = 1000\n\nall_null_Ts = np.zeros(n_sim)\n\nfor cur_sim in range(n_sim):\n    ## permute the first column of data_pairs\n    cur_sim_data = np.column_stack((np.random.choice(data_pairs[:, 0], n, replace=False), data_pairs[:, 1]))\n\n    ## convert cur_sim_data to contingency table\n    cur_sim_con_table = np.zeros((K2, K1))\n    for i in range(n):\n        cur_sim_con_table[cur_sim_data[i, 0], cur_sim_data[i, 1]] += 1\n    \n    null_T = np.sum((cur_sim_con_table - E)**2 / E)\n    all_null_Ts[cur_sim] = null_T\n\nprint(cur_sim_con_table)\n\n## compute p-value\np_value = np.mean(all_null_Ts &gt;= obs_T)\nprint(f\"Simulated p-value using test statistic 1 = {p_value}\")\n\nplt.hist(all_null_Ts, bins=12);\nplt.axvline(obs_T, color='red');\n\n[[ 332. 1205.  463.]\n [  38.  115.   47.]]\nSimulated p-value using test statistic 1 = 0.011\n\n\n\n\n\n\n\n\n\n\n## Use traditional pearson chi-squared test\nfrom scipy.stats import chi2_contingency\n\nchi2, p, dof, expected = chi2_contingency(con_table)\nprint(f\"CLT-based p-value = {p:.4f}\")\n\nCLT-based p-value = 0.0053\n\n\n\n\nExample 1.5: independence test for continuous data\n\n# Creating the X matrix\nX = np.array([[2.5, 2.7], [4, 4.0], [5, 3.2], [1, 2.7], [3, 3.2], [2, 2.4], [1.5, 2.1]])\n\n## plot variable X[, 0] vs X[, 1]\nplt.scatter(X[:, 0], X[:, 1])\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\n\nnp.corrcoef(X[:, 0], X[:, 1])[0, 1]\n\nnp.float64(0.7350457786848433)\n\n\n\n\n\n\n\n\n\n\nn = X.shape[0]\n\n# Calculating the correlation of the original data\nobs_T = np.corrcoef(X[:, 0], X[:, 1])[0, 1]\n\nn_sim = 1000\n\nnull_Ts = np.zeros(n_sim)\n\nfor cur_sim in range(n_sim):\n    # Shuffling only the first column of X\n    Xprime = np.column_stack((np.random.choice(X[:, 0], n, replace=False), X[:, 1]))\n    null_Ts[cur_sim] = np.corrcoef(Xprime[:, 0], Xprime[:, 1])[0, 1]\n\n# Calculating the proportion of simulations where the absolute correlation is greater than my_corr\nsim_pval = np.sum(np.abs(null_Ts) &gt;= obs_T) / n_sim\n\nprint(f\"Simulated p-value: {sim_pval}\")\n\nplt.hist(null_Ts, bins=12)\nplt.axvline(obs_T, color='red')\nplt.show()\n\nSimulated p-value: 0.046\n\n\n\n\n\n\n\n\n\n\n\nExample 1.6: independence test using Spearman’s rho\n\nx = np.arange(1, 20)\ny = np.arange(1, 20)\ny[-1] = -50\n\nn = len(x)\n\nplt.figure(figsize=(5,4))\nplt.scatter(x, y);\nplt.xlabel('x');\nplt.ylabel('y');\n\n\n\n\n\n\n\n\n\n# correlation of original data\nobs_corr = np.corrcoef(x, y)[0,1]\n# spearman rho\nrank_x = stats.rankdata(x)\nrank_y = stats.rankdata(y)\nobs_spearman = np.corrcoef(rank_x, rank_y)[0,1]\n\nn_sim = 1000\n\nnull_corr = np.zeros(n_sim)\nnull_spearman = np.zeros(n_sim)\n\nfor cur_sim in range(n_sim):\n    \n    x_shuffle = np.random.choice(x, n, replace=False) \n    null_corr[cur_sim] = np.corrcoef(x_shuffle, y)[0, 1]\n    rank_x = stats.rankdata(x_shuffle)\n    null_spearman[cur_sim] = np.corrcoef(rank_x, rank_y)[0, 1]\n\n# Calculating the proportion of simulations where the absolute correlation is greater than obs_corr\ncorr_pval = np.sum(np.abs(null_corr) &gt;= obs_corr) / n_sim\nprint(f\"Simulated correlation p-value: {corr_pval}\")\n\nspearman_pval = np.sum(np.abs(null_spearman) &gt;= obs_spearman) / n_sim\nprint(f\"Simulated spearman's p-value: {spearman_pval}\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n\nax1.hist(null_corr, bins=12)\nax1.axvline(obs_corr, color='red')\nax1.set_title('Independence test with correlation')\n\nax2.hist(null_spearman, bins=12)\nax2.axvline(obs_spearman, color='red')\nax2.set_title('Independence test with Spearmans rho')\n\nplt.show()\n\nSimulated correlation p-value: 1.0\nSimulated spearman's p-value: 0.0",
    "crumbs": [
      "Home",
      "Lecture 1 - Monte Carlo"
    ]
  },
  {
    "objectID": "nb/lec1.html#estimating-sampling-distributions",
    "href": "nb/lec1.html#estimating-sampling-distributions",
    "title": "Lecture 1 - Monte Carlo",
    "section": "Estimating sampling distributions",
    "text": "Estimating sampling distributions\nGoal: Given a sample X_1,\\dots, X_n\\sim p(x|\\theta), what is the standard error for an estimator \\widehat{\\theta} of \\theta?\n\nFor example, the sample mean \\bar{X} is an estimator for the population mean \\mu. The Central Limit Theorem tells us that \\bar{X} \\sim N(\\mu, \\sigma^2/n), where \\sigma^2 is the population variance.\n\nMonte Carlo: use repeated sampling from p(x|\\theta)\n\nExample: obtain sampling distribution of the median of the exponential distribution\n\nDraw S samples, each of size n, from the exponential distribution\nFor each sample, calculate the median \\widehat{\\theta}^{(s)} = \\text{median}(X_1^{(s)}, \\dots, X_n^{(s)})\nNow you have an approximate distribution based on (\\widehat{\\theta}^{(1)},\\dots, \\widehat{\\theta}^{(S)})",
    "crumbs": [
      "Home",
      "Lecture 1 - Monte Carlo"
    ]
  },
  {
    "objectID": "nb/lec1.html#the-bootstrap",
    "href": "nb/lec1.html#the-bootstrap",
    "title": "Lecture 1 - Monte Carlo",
    "section": "The Bootstrap",
    "text": "The Bootstrap\nProblem: If we do not know p(x|\\theta), we cannot repeatedly sample from the population\nThe bootstrap (Efron, 1979) refers to a simulation-based approach to understand the accuracy of statistical estimates.\n\nInstead of sampling from p(x|\\theta), the bootstrap involves sampling from an observed sample x_1,\\dots, x_n, with replacement\nThat is, the bootstrap approximates p(x|\\theta) with the empirical distribution of x_1,\\dots, x_n.\n\n\n\nExample 1.7: confidence interval for the median\nHere is a sample X_1,\\dots, X_n from the exponential distribution.\n\n# draw sample\nnp.random.seed(42)\nn = 30\nx = np.random.exponential(scale=1, size=n)  \n\n# calculate sample estimate\nmed_hat = np.median(x)\n\n# get population distribution for plotting\nx_vals = np.linspace(0, 10, 100)\npdf_vals = scipy.stats.expon.pdf(x_vals)\n\nplt.figure(figsize=(4,3))\nplt.plot(x_vals, pdf_vals, 'r', label='Population');\nplt.hist(x, density=True, label='Sample', bins=20);\nplt.title('Exponential Distribution');\nplt.legend();\n\n\n\n\n\n\n\n\n\nprint(f\"Estimated: {med_hat:.3f}\")\n\nWe use the bootstrap to obtain bootstrap samples, and calculate the median of each of the samples.\n\nn_boot = 1000\n\nboot_med_hats = np.zeros(n_boot)\n\nfor cur_boot in range(n_boot):\n    xboot = np.random.choice(x, n, replace=True)\n    boot_med_hats[cur_boot] = np.median(xboot)\n\n\nplt.figure(figsize=(4,3))\nbins_medians = np.linspace(min(boot_med_hats), max(boot_med_hats), 15)\nplt.hist(boot_med_hats, bins=bins_medians,density=True, color='grey', alpha=0.7);\nplt.title('Bootstrap Sample Medians');\n\n\n\n\n\n\n\n\nWe show two ways to compute a confidence interval for the sample median, \\widehat{m}\n\nNormal approximation using standard deviation of bootstrap medians\n\n [\\widehat{m} - z_{1-\\alpha/2} sd(\\widehat{m}), \\widehat{m} + z_{1-\\alpha/2} sd(\\widehat{m})]\nwhere z_{1-\\alpha/2} is the 1-\\alpha/2 quantile of the Gaussian distribution.\n\nz_alpha = stats.norm.ppf(0.975)  # z_{1-alpha/2} for alpha=0.05\nlower_quantile = med_hat - z_alpha * np.std(boot_med_hats)\nupper_quantile = med_hat + z_alpha * np.std(boot_med_hats)\n\n\nprint(f\"Bootstrap normal confidence interval: ({lower_quantile:.3f}, {upper_quantile:.3f})\")\n\nBootstrap normal confidence interval: (0.198, 0.837)\n\n\n\n\n\n\n\n\n\n\n\n\nQuantiles of bootstrap medians\n\n [\\widehat{Q}_{\\alpha/2}, \\widehat{Q}_{1-\\alpha/2}]\nwhere \\widehat{Q}_{\\alpha/2} is the \\alpha/2 sample quantile of the bootstrap medians.\n\nq025 = np.quantile(boot_med_hats, 0.025)\nq975 = np.quantile(boot_med_hats, 0.975)\nprint(f\"Bootstrap quantile confidence interval: ({q025:.3f}, {q975:.3f})\")\n\nBootstrap quantile confidence interval: (0.291, 0.905)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.8: verifying the validity of bootstrap confidence intervals\nWe show the bootstrap confidence intervals have almost (1-\\alpha)/% coverage.\n\nWe draw a sample from the Poisson(\\lambda) distribution with \\lambda=1. The population mean is 1.\nWe draw bootstrap samples and calculate a confidence interval for the mean using the normal approximation\nWe then record how many intervals contain the population mean\n\n\nn_sim = 500\nsuccesses = np.zeros(n_sim)\nz_alpha = stats.norm.ppf(0.975)  # z_{1-alpha/2} for alpha=0.05\nlower_bounds = []\nupper_bounds = []\n\nfor cur_sim in range(n_sim):\n    n = 50\n    x = np.random.poisson(lam=1, size=n)  # Poisson distribution with lambda=1\n    mu = 1\n\n    muhat = np.mean(x)\n\n    n_boot = 500\n    boot_muhats = np.zeros(n_boot)\n    \n    for cur_boot in range(n_boot):\n        xboot = np.random.choice(x, n, replace=True)\n        boot_muhats[cur_boot] = np.mean(xboot)\n\n    boot_std = np.std(boot_muhats) \n    boot_ci = [muhat - z_alpha * boot_std, muhat + z_alpha * boot_std]\n    lower_bounds.append(muhat - z_alpha * boot_std)\n    upper_bounds.append(muhat + z_alpha * boot_std)\n\n    if boot_ci[0] &lt;= mu &lt;= boot_ci[1]:\n        successes[cur_sim] = 1\n\npercent_success = np.sum(successes) / n_sim\n\nprint(f\"Percent of experiments where the confidence interval contains the true mean: {percent_success}\")\n\n# Plot the confidence intervals\nfig, ax = plt.subplots(figsize=(10, 6))\nfor i in range(n_sim):\n    color = 'blue' if successes[i] else 'red'\n    ax.hlines(i, lower_bounds[i], upper_bounds[i], colors=color, linewidth=0.5)\n\nax.axvline(mu, color='black', linestyle='--', label='True mean')\nax.set_xlabel('Mean value')\nax.set_ylabel('Simulation index')\nax.set_title('Bootstrap Confidence Intervals')\nax.legend()\nplt.show()\n\nPercent of experiments where the confidence interval contains the true mean: 0.92\n\n\n\n\n\n\n\n\n\n\n\nExample 1.9 and 1.10: bootstrap tests for the mean\n\nX = np.array([0.2, -1.9, 1.4, -2.7, -1.7, -1.4, 0.3, 1.2, -1.1, -0.2, -2.1])\nn = len(X)\n\nn_boot = 1000\n\nprint(f\"mean of X: {np.mean(X):.3f}  with n={n}\")\n\nobs_T = abs(np.mean(X))\n\nXc = X - np.mean(X)\n\nboot_Ts = np.zeros(n_boot)\n\nfor cur_boot in range(n_boot):\n  Xboot = np.random.choice(Xc, n, replace=True)\n  boot_Ts[cur_boot] = abs(np.mean(Xboot))\n\nboot_pval = sum(boot_Ts &gt;= obs_T)/n_boot\n\nprint(f\"bootstrap p-value: {boot_pval}\")\n\nplt.hist(boot_Ts, bins=12)\nplt.axvline(np.abs(obs_T), color='red', linestyle='dashed')\n\nplt.show()\n\nmean of X: -0.727  with n=11\nbootstrap p-value: 0.078\n\n\n\n\n\n\n\n\n\n\nX = np.array([-1, 3, 5, 1, 10, 2, 9, 6, 6, 2, 4])\nY = np.array([11, -2, 1, 0, 0, 5, 2])\n\nn = len(X)\nm = len(Y)\n\nn_boot = 1000\n\nXc = X - np.mean(X)\nYc = Y - np.mean(Y)\n\nprint(f\"mean of X: {np.mean(X):.3f},  mean of Y: {np.mean(Y):.3f}\")\n\nobs_T = np.mean(X) - np.mean(Y)\n\nboot_Ts = np.zeros(n_boot)\n\nfor cur_boot in range(n_boot):\n  Xboot = np.random.choice(Xc, n, replace=True)\n  Yboot = np.random.choice(Yc, m, replace=True)\n  boot_Ts[cur_boot] = np.mean(Xboot) - np.mean(Yboot)\n\nboot_pval = sum(np.abs(boot_Ts) &gt;= np.abs(obs_T))/n_boot\n\nprint(f\"bootstrap p-value: {boot_pval}\")\n\nplt.hist(boot_Ts, bins=12)\nplt.axvline(np.abs(obs_T), linestyle='dashed', color='red')\nplt.axvline(-np.abs(obs_T), linestyle='dashed', color='red')\n\nplt.show()\n\nmean of X: 4.273,  mean of Y: 2.429\nbootstrap p-value: 0.324",
    "crumbs": [
      "Home",
      "Lecture 1 - Monte Carlo"
    ]
  },
  {
    "objectID": "nb/lec2a.html",
    "href": "nb/lec2a.html",
    "title": "Lecture 2a - Multiple Testing",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.stats import t\nfrom scipy.stats import ttest_1samp\n\ntorch.manual_seed(42)\n\n&lt;torch._C.Generator at 0x12031c3f0&gt;",
    "crumbs": [
      "Home",
      "Lecture 2a - Multiple Testing"
    ]
  },
  {
    "objectID": "nb/lec2a.html#warm-up",
    "href": "nb/lec2a.html#warm-up",
    "title": "Lecture 2a - Multiple Testing",
    "section": "Warm up",
    "text": "Warm up\nLet’s toss a coin 10 times.\n\nsample = np.random.binomial(10,0.5)\n\n\nsample\n\n5\n\n\nLet’s repeat this 10,000 times.\nHow many times will we see 10 heads and 0 tails?\n\nnsim = 10000\nnheads = np.zeros((nsim))\n\nfor i in range(nsim):\n    sample = np.random.binomial(10,0.5)\n    nheads[i] = sample\n\n\nplt.hist(nheads);\n\n\n\n\n\n\n\n\n\nsum(nheads == 0)\n\nnp.int64(9)\n\n\nIf we do enough tests, we will see rare things, even when the null hypothesis is true!\nHow do we account for this?",
    "crumbs": [
      "Home",
      "Lecture 2a - Multiple Testing"
    ]
  },
  {
    "objectID": "nb/lec2a.html#multiple-testing",
    "href": "nb/lec2a.html#multiple-testing",
    "title": "Lecture 2a - Multiple Testing",
    "section": "Multiple testing",
    "text": "Multiple testing\nWe run one-sample t-tests for m hypotheses.\nWe do the following corrections:\n\nBonferroni\nHolms\nBenjamini-Hochberg\n\n\nExample: No actual signal\n\nn = 40        # number of samples\nm = 1000         # number of features\n\nX = np.random.normal(size = (n, m))\n#h0 is true\n\n\nX[:, 0]\n\narray([ 1.1590115 ,  0.29437799, -1.20388884, -1.39994129,  0.80287114,\n       -0.66532837,  0.94760322, -1.02684096, -0.53667259,  1.26035408,\n        0.30475883, -0.68428187, -0.7424497 , -1.19441991, -0.6307807 ,\n        1.08867092,  0.65729084,  0.02539257,  1.05287459, -1.93841006,\n        2.17832052, -2.4701497 ,  2.02294352,  0.06927303,  0.54318123,\n        1.9602065 , -0.35964106,  1.04538793, -1.52884496,  0.34965436,\n       -1.33769048,  0.6165512 ,  0.67023305, -1.11043292,  0.9638287 ,\n       -0.46430343, -0.41250436, -0.30909244, -0.02039219, -0.3204189 ])\n\n\n\nplt.scatter(range(m), X.mean(axis=0))\n\n\n\n\n\n\n\n\n\ndef ttest_1(x, h0_mean=0):\n\n    df = n-1\n\n    mean = x.mean() # sample mean x_bar\n    d = mean - h0_mean # x_bar - mu   (mu=0 under H_0)\n    v = np.var(x) # sample variance\n    denom = np.sqrt(v / n) # variance of sample mean\n    tstat = np.abs(d / denom)\n    # xmean - h0_mean / (sqrt(var/n))\n\n    # our test-stat is a t distributed random variable with n-1 degrees of freedom\n\n    pval = t.cdf(-tstat, df = df) + (1 - t.cdf(tstat, df = df)) \n\n    # pval - probability in the lower and upper tails of our t distribution\n\n    return pval\n\n\npvals = np.zeros((m))\nfor j in range(m):\n    pvals[j] = ttest_1samp(X[:, j], 0).pvalue\n\n\n# no multiple testing correction\n# we expect to reject m * 0.05 samples\nalpha  = 0.05\nnmp = np.where(pvals &lt; alpha)[0]\nprint(\"No multiple testing correction: reject \", nmp.shape[0])\n\nNo multiple testing correction: reject  45\n\n\n\n# bonferroni\nbf = np.where(pvals &lt; alpha/m)[0]\nprint(\"Bonferroni: reject \", bf.shape[0])\n\nBonferroni: reject  0\n\n\n\n# holms\nord_pvals = np.argsort(pvals)\nholms = []\nfor j, s in enumerate(ord_pvals):\n    #j = 0, s is index of smallest p-val\n    denom = m - j\n    if pvals[s] &lt;= (alpha/denom):\n        holms.append(s)\n    else:\n        break\nprint(\"Holms: reject \", len(holms))\n\nHolms: reject  0\n\n\n\n# BH procedure # this is different from holms and bonferroni in that \n# we control FDR, not FWER\nq = 0.05\nbh = []\nfor j, s in enumerate(ord_pvals):\n    val = q * (j + 1) /m # zero indexing\n    if pvals[s] &lt;= val:\n        bh.append(s)\n    else:\n        break\n\nprint(\"Benjamini-Hochberg: reject \", len(bh))\n\nBenjamini-Hochberg: reject  0\n\n\n\nplt.figure(figsize=(6, 6))\nplt.scatter(range(m), pvals[ord_pvals], alpha=0.6, label='P-values')\n\nplt.axhline(y=alpha/m, color='b', linestyle='--', label='Bonferroni correction', linewidth=2)\n# Holms correction line\nholms_threshold = alpha / (m - np.arange(m))\nplt.plot(range(m), holms_threshold, 'r--', label='Holms correction', linewidth=2)\n\n# Benjamini-Hochberg correction line\nbh_threshold = (alpha / m) * (np.arange(m) + 1)\nplt.plot(range(m), bh_threshold, 'g--', label='Benjamini-Hochberg correction', linewidth=2)\n\nplt.xlabel('Index (ordered by p-value)')\nplt.ylabel('P-value')\nplt.legend()\nplt.yscale('log')\nplt.xscale('log')\nplt.title('Ordered P-values with Multiple Testing Corrections')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nExample: Some signal to detect\n\ntrue_mean = np.array([1.0] * int(m*5/100) + [0] * int(m * 95/100))\n\nX = np.random.normal(size = (n, m))\nX = X + true_mean\n\nplt.scatter(range(m), X.mean(axis=0))\n\n\n\n\n\n\n\n\n\nprint('Number of hypotheses we should reject: ', int(m * 5/100))\n\nNumber of hypotheses we should reject:  50\n\n\n\npvals = np.zeros((m))\nfor j in range(m):\n    pvals[j] = ttest_1samp(X[:, j], 0).pvalue\n\n\n# no multiple testing correction\nalpha  = 0.05\nnmp = np.where(pvals &lt; alpha)[0]\nprint(\"No multiple testing correction: reject \", nmp.shape[0])\n\nNo multiple testing correction: reject  94\n\n\n\n# bonferroni\nbon = np.where(pvals &lt; alpha/m)[0]\nprint(\"Bonferroni: reject \", bon.shape[0])\n\nBonferroni: reject  46\n\n\n\n\n# holms\nord_pvals = np.argsort(pvals)\nholms = []\nfor j, s in enumerate(ord_pvals):\n    denom = m - j\n    if pvals[s] &lt;= (alpha/denom):\n        holms.append(s)\n    else:\n        break\nprint(\"Holms: reject \", len(holms))\n\nHolms: reject  46\n\n\n\n# BH procedure\nq = 0.05\nbh = []\nfor j, s in enumerate(ord_pvals):\n    val = q * (j + 1) /m # zero indexing\n    if pvals[s] &lt;= val:\n        bh.append(s)\n    else:\n        break\n\nprint(\"Benjamini-Hochberg: reject \", len(bh))\n\nBenjamini-Hochberg: reject  55\n\n\n\nplt.figure(figsize=(6, 6))\nplt.scatter(range(m), pvals[ord_pvals], alpha=0.6, label='P-values')\n\nplt.axhline(y=alpha/m, color='b', linestyle='--', label='Bonferroni correction', linewidth=2)\n# Holms correction line\nholms_threshold = alpha / (m - np.arange(m))\nplt.plot(range(m), holms_threshold, 'r--', label='Holms correction', linewidth=2)\n\n# Benjamini-Hochberg correction line\nbh_threshold = (alpha / m) * (np.arange(m) + 1)\nplt.plot(range(m), bh_threshold, 'g--', label='Benjamini-Hochberg correction', linewidth=2)\n\nplt.xlabel('Index (ordered by p-value)')\nplt.ylabel('P-value')\nplt.yscale('log')\nplt.xscale('log')\nplt.legend()\nplt.title('Ordered P-values with Multiple Testing Corrections')\nplt.grid(True, alpha=0.3)\nplt.show()",
    "crumbs": [
      "Home",
      "Lecture 2a - Multiple Testing"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rutgers STAT-486 - Statistical Learning",
    "section": "",
    "text": "Instructor: Gemma Moran\nInstructor website: link"
  },
  {
    "objectID": "index.html#spring-2026",
    "href": "index.html#spring-2026",
    "title": "Rutgers STAT-486 - Statistical Learning",
    "section": "",
    "text": "Instructor: Gemma Moran\nInstructor website: link"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Rutgers STAT-486 - Statistical Learning",
    "section": "Getting started",
    "text": "Getting started\nSee here for details about how to get started with python, VSCode and PyTorch."
  },
  {
    "objectID": "index.html#lectures",
    "href": "index.html#lectures",
    "title": "Rutgers STAT-486 - Statistical Learning",
    "section": "Lectures",
    "text": "Lectures\nThe code from the lectures is in the left sidebar.\nLecture slides and information about homeworks, office hours etc. can be found on Canvas."
  },
  {
    "objectID": "nb/lec2b.html",
    "href": "nb/lec2b.html",
    "title": "Lecture 2b - Supervised Learning",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\nnp.random.seed(1)\n\nimport warnings\nwarnings.filterwarnings('ignore')",
    "crumbs": [
      "Home",
      "Lecture 2b - Supervised Learning"
    ]
  },
  {
    "objectID": "nb/lec2b.html#data",
    "href": "nb/lec2b.html#data",
    "title": "Lecture 2b - Supervised Learning",
    "section": "Data",
    "text": "Data\nWe consider the Kings County housing dataset. It includes homes sold between May 2014 and May 2015.\nSpecifically, we focuse on the Rainier Valley zipcode.\n\n# Load the dataset\nhouse = pd.read_csv(\"data/rainier_valley_house.csv\")\n\nHere are the features:\n\nhouse.columns\n\nIndex(['Unnamed: 0', 'id', 'date', 'price', 'bedrooms', 'bathrooms',\n       'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition',\n       'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n       'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n      dtype='object')\n\n\n\n# number of houses\nprint(f\"number of houses:  {house.shape[0]}\")\n\nplt.boxplot(house['price'])\nplt.title('Price Boxplot')\n# make plot small in jupyter output\nplt.gcf().set_size_inches(4, 3)\n\nplt.show()\n\nnumber of houses:  508\n\n\n\n\n\n\n\n\n\n\n## For houses with 0, 1, 2, ... bedrooms, show their median price\nprint(house.groupby('bedrooms')['price'].median().reset_index())\n\n   bedrooms     price\n0         0  228000.0\n1         1  299000.0\n2         2  325000.0\n3         3  365000.0\n4         4  447500.0\n5         5  425000.0\n6         6  462500.0\n7         7  370500.0\n\n\n\n# Filtering houses priced under 1 million\nhouse = house[house['price'] &lt; 1e6]\n\n\n## Plot year built vs. price\nplt.scatter(house['yr_built'], house['price'], alpha=0.1)\nplt.xlabel('Year Built')\nplt.ylabel('Price')\nplt.title('Year Built vs. Price')\nplt.gcf().set_size_inches(4, 3)\nplt.show()\n\n## Smooth scatter plot of year built vs. price\nplt.scatter(house['yr_built'], house['price'], alpha=0.1, label='Data')\nz = np.polyfit(house['yr_built'], house['price'], 1)\np = np.poly1d(z)\nplt.plot(house['yr_built'], p(house['yr_built']), \"r--\", label='Trend')\nplt.xlabel('Year Built')\nplt.ylabel('Price')\nplt.title('Smooth Scatter Plot: Year Built vs. Price')\nplt.legend()\nplt.gcf().set_size_inches(4, 3)\nplt.show()\n\n## Plot year built vs. sqft_living\nplt.scatter(house['yr_built'], house['sqft_living'], alpha=0.1)\nplt.xlabel('Year Built')\nplt.ylabel('Sqft Living')\nplt.title('Year Built vs. Sqft Living')\nplt.gcf().set_size_inches(4, 3)\nplt.show()\n\n\n## Pairwise plot of price, bedrooms, and sqft_living\n#pd.plotting.scatter_matrix(house[['price', 'bedrooms', 'sqft_living']], alpha=0.1, figsize=(10, 10))\n#plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Group by condition and calculate mean price\nprint(house.groupby('condition')['price'].mean().reset_index())\n\n   condition          price\n0          1  227000.000000\n1          2  246749.705882\n2          3  396841.120482\n3          4  420201.384615\n4          5  433258.152174\n\n\n\nplt.figure(figsize=(10, 8))\nsc = plt.scatter(house['long'], house['lat'], c=house['price'], cmap='viridis', alpha=0.5)\nplt.colorbar(sc, label='Price ($)')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.title('House Location and Price')\nplt.gcf().set_size_inches(5, 4)\nplt.show()",
    "crumbs": [
      "Home",
      "Lecture 2b - Supervised Learning"
    ]
  },
  {
    "objectID": "nb/lec2b.html#k-nearest-neighbors",
    "href": "nb/lec2b.html#k-nearest-neighbors",
    "title": "Lecture 2b - Supervised Learning",
    "section": "K-Nearest Neighbors",
    "text": "K-Nearest Neighbors\n\n# We will consider this subset of features\nfeatures = [\"floors\", \"grade\", \"condition\", \"view\", \"sqft_living\",\n            \"sqft_lot\", \"sqft_basement\", \"yr_built\", \"yr_renovated\",\n            \"bedrooms\", \"bathrooms\", \"lat\", \"long\"]\n\nY = house['price'] / 1000\nX = house[features]\n\n## Standardize the features\nscaler = StandardScaler()\nX_stan = scaler.fit_transform(X)\n\n## Split the data into training and test sets\nn_train = 400\nn_test = 100\n\nidx = np.random.permutation(len(Y))\nX_stan = X_stan[idx]\nY = Y.iloc[idx]\n\nX_train = X_stan[:n_train]\nX_test = X_stan[n_train:(n_train + n_test)]\nY_train = Y[:n_train]\nY_test = Y[n_train:n_train + n_test]\n\n## Implement KNN\nK = 7\nY_pred = []\n\nfor test_point in X_test:\n    distances = np.sqrt(((X_train - test_point)**2).sum(axis=1))\n    nearest_neighbors_indices = distances.argsort()[:K]\n    Y_pred.append(Y_train.iloc[nearest_neighbors_indices].mean())\n\nY_pred = np.array(Y_pred)\nY_pred_baseline = Y_train.mean()\n\n# Evaluate test error\ntest_error = np.sqrt(((Y_test - Y_pred) ** 2).mean())\nbaseline_error = np.sqrt(((Y_test - Y_pred_baseline) ** 2).mean())\nprint(f\"Test RMSE of KNN: {test_error:.3f}   Baseline RMSE: {baseline_error:.3f}\")\n\n#print test R-squared\nR2 = 1 - test_error**2 / baseline_error**2\nprint(f\"Test R-squared of KNN: {R2:.3f}\")\n\nTest RMSE of KNN: 243.110   Baseline RMSE: 333.415\nTest R-squared of KNN: 0.468\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# Split the data into training and test sets\nX_train, X_test, Y_train, Y_test = train_test_split(X_stan, Y, test_size=100, train_size=400, random_state=1)\n\nall_errs = []\n\nfor K in range(1, 30):\n    knn = KNeighborsRegressor(n_neighbors=K)\n    knn.fit(X_train, Y_train)\n    Y_pred = knn.predict(X_test)\n\n    # Evaluate test error\n    test_error = np.sqrt(((Y_test - Y_pred) ** 2).mean())\n    all_errs.append(test_error)\n\nplt.plot(range(1, 30), all_errs, marker='o')",
    "crumbs": [
      "Home",
      "Lecture 2b - Supervised Learning"
    ]
  },
  {
    "objectID": "nb/lec2b.html#linear-regression",
    "href": "nb/lec2b.html#linear-regression",
    "title": "Lecture 2b - Supervised Learning",
    "section": "Linear regression",
    "text": "Linear regression\n\n## linear regression\nX_stan1 = np.hstack([np.ones((X_stan.shape[0], 1)), X_stan])\nX_train, X_test, Y_train, Y_test = train_test_split(X_stan1, Y, test_size=100, train_size=400, random_state=2)\n\nbetahat = np.linalg.solve(X_train.T @ X_train, X_train.T @ Y_train)\nY_pred = X_test @ betahat\n\ntest_error = np.sqrt(((Y_test - Y_pred) ** 2).mean())\nbaseline_error = np.sqrt(((Y_test - Y_train.mean()) ** 2).mean())\n\n## print coefficients\nprint(\"Coefficients:\")\nfeatures = X.columns\nfor i, f in enumerate(features):\n    print(f\"{f}: {betahat[i]:.3f}\")\n\n\nprint(f\"Test RMSE of linear regression: {test_error:.3f}   Baseline RMSE: {baseline_error:.3f}\")\n\nR2 = 1 - test_error**2 / baseline_error**2\nprint(f\"Test R-squared of linear regression: {R2:.3f}\")\n\nCoefficients:\nfloors: 416.418\ngrade: 12.421\ncondition: 58.902\nview: 18.317\nsqft_living: 44.802\nsqft_lot: 87.841\nsqft_basement: 87.671\nyr_built: -17.770\nyr_renovated: -9.817\nbedrooms: 6.158\nbathrooms: -33.250\nlat: 9.441\nlong: 72.392\nTest RMSE of linear regression: 94.613   Baseline RMSE: 195.243\nTest R-squared of linear regression: 0.765\n\n\n\n## use sklearn to do linear regression\nfrom sklearn.linear_model import LinearRegression\n\nlinreg = LinearRegression()\nlinreg.fit(X_train, Y_train)\nY_pred = linreg.predict(X_test)\n\ntest_error = np.sqrt(((Y_test - Y_pred) ** 2).mean())\nbaseline_error = np.sqrt(((Y_test - Y_train.mean()) ** 2).mean())\n\nprint(f\"Test RMSE of linear regression: {test_error:.3f}   Baseline RMSE: {baseline_error:.3f}\")\n\nR2 = 1 - test_error**2 / baseline_error**2\nprint(f\"Test R-squared of linear regression: {R2:.3f}\")\n\nTest RMSE of linear regression: 94.613   Baseline RMSE: 195.243\nTest R-squared of linear regression: 0.765",
    "crumbs": [
      "Home",
      "Lecture 2b - Supervised Learning"
    ]
  },
  {
    "objectID": "nb/getting-started.html",
    "href": "nb/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "We will use Python via the Anaconda distribution.\nDownload Anaconda here.\n\n\n\n\n\n\nNote\n\n\n\nThere are a variety of different Python distributions; for statistics and machine learning, we recommend Anaconda as it comes with many useful packages pre-installed.\n(It is also a good idea NOT to use your computer’s pre-installed Python - you don’t want to accidentally change any system settings!)\n\n\nAnaconda requires a few GBs of storage - a more lightweight version is Miniconda, which you can download here.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "nb/getting-started.html#anaconda-installation",
    "href": "nb/getting-started.html#anaconda-installation",
    "title": "Getting started",
    "section": "",
    "text": "We will use Python via the Anaconda distribution.\nDownload Anaconda here.\n\n\n\n\n\n\nNote\n\n\n\nThere are a variety of different Python distributions; for statistics and machine learning, we recommend Anaconda as it comes with many useful packages pre-installed.\n(It is also a good idea NOT to use your computer’s pre-installed Python - you don’t want to accidentally change any system settings!)\n\n\nAnaconda requires a few GBs of storage - a more lightweight version is Miniconda, which you can download here.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "nb/getting-started.html#vscode",
    "href": "nb/getting-started.html#vscode",
    "title": "Getting started",
    "section": "VSCode",
    "text": "VSCode\nThere are a number of Python IDEs (integrated development environments). In class, we will be using VSCode (download here).",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "nb/getting-started.html#managing-packages",
    "href": "nb/getting-started.html#managing-packages",
    "title": "Getting started",
    "section": "Managing packages",
    "text": "Managing packages\nThere are many open source Python packages for statistics and machine learning.\nTo download packages, two popular package managers are Conda and Pip. Both Conda and Pip come with the Anaconda distribution.\nConda is a general-purpose package management system, designed to build and manage software of any type from any language. This means conda can take advantage of many non-python packages (like BLAS, for linear algebra operations).\nPip is a package manager for python. You may see people using pip with environments using virtualenv or venv.\nWe recommend:\n\nuse a conda environment\nwithin this environment, use conda to install base packages such as pandas and numpy\nif a package is not available via conda, then use pip\n\nSee here for some conda vs pip misconceptions, and why conda is helpful.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "nb/getting-started.html#environments",
    "href": "nb/getting-started.html#environments",
    "title": "Getting started",
    "section": "Environments",
    "text": "Environments\n\nAbout\nIt is good coding practice to use virtual environments with Python. From this blog:\n\nA Python virtual environment consists of two essential components: the Python interpreter that the virtual environment runs on and a folder containing third-party libraries installed in the virtual environment. These virtual environments are isolated from the other virtual environments, which means any changes on dependencies installed in a virtual environment don’t affect the dependencies of the other virtual environments or the system-wide libraries. Thus, we can create multiple virtual environments with different Python versions, plus different libraries or the same libraries in different versions.\n\n\n\n\nCreating an environment for STAT-486\nWe recommend creating a virtual environment for your STAT-486 coding projects. This way, you can have an environment with all the necessary packages and you can easily keep track of what versions of the packages you used.\n\nOpen Terminal (macOS) or a shell. You can also use Terminal in VSCode.\nCreate an environment called stat486 using Conda with the command: conda create --name stat486\nTo install packages in your environment, first activate your environment: conda activate stat486\nThen, install the following packages using the command: conda  install numpy pandas scikit-learn matplotlib seaborn jupyter ipykernel\nInstall PyTorch by running the appropriate command from here (for macOS, the command is: pip3 install torch torchvision)\nTo exit your environment: conda deactivate\n\nHere is a helpful cheatsheet for conda environment commands.\nFor more details about the shell / bash, here is a helpful resource.\n\n\nJupyter Notebooks\n\nDownload lec1.ipynb here and open it in VSCode.\nTo use your stat486 environment, on the top right hand corner, click “Select Kernel” &gt; “Python Environments” &gt; stat486. If it prompts you to install ipykernel, follow the prompts to install it.\n\nJupyter notebooks (.ipynb files) are useful to combine code cells with text (as markdown cells).\nVSCode also has a Python interactive window (details here).",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "nb/getting-started.html#learning-python",
    "href": "nb/getting-started.html#learning-python",
    "title": "Getting started",
    "section": "Learning Python",
    "text": "Learning Python\nHere are some resources for learning Python:\n\nNumpy\nPandas\nObject-oriented programming",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  }
]